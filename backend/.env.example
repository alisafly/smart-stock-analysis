# AI大模型配置示例文件
# 复制此文件内容到 backend/.env 文件中

# ===========================================
# AI服务提供商配置
# ===========================================
# 可选值: openai, lmstudio, disabled
AI_PROVIDER=openai

# ===========================================
# OpenAI 配置 (使用自定义API)
# ===========================================
OPENAI_API_KEY=your_api_key_here
OPENAI_BASE_URL=https://api.zhizengzeng.com/v1
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# ===========================================
# LMStudio 本地大模型配置
# ===========================================
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=local-model
LMSTUDIO_MAX_TOKENS=2000
LMSTUDIO_TEMPERATURE=0.7

# ===========================================
# AI分析功能配置
# ===========================================
AI_ENABLE_STOCK_ANALYSIS=true
AI_MAX_HISTORY_CONTEXT=5

# ===========================================
# 使用指南
# ===========================================

## 1. OpenAI 配置步骤：
# 1.1 将 AI_PROVIDER 设置为 "openai"
# 1.2 设置您的 OPENAI_API_KEY
# 1.3 确认 OPENAI_BASE_URL 为您的API地址
# 1.4 根据需要调整模型和参数

## 2. LMStudio 配置步骤：
# 2.1 下载并安装 LMStudio (https://lmstudio.ai/)
# 2.2 在 LMStudio 中加载本地模型
# 2.3 启动本地服务器 (默认端口1234)
# 2.4 将 AI_PROVIDER 设置为 "lmstudio"
# 2.5 确认 LMSTUDIO_BASE_URL 地址正确

## 3. 禁用AI功能：
# 将 AI_PROVIDER 设置为 "disabled"，系统将使用本地规则引擎

## 4. 测试配置：
# 启动后端服务后，访问 http://localhost:3002/api/chat/status
# 查看AI服务配置状态

# ===========================================
# 常见问题解决
# ===========================================

## Q: OpenAI API调用失败？
# A: 检查API密钥是否正确，网络是否可访问API地址

## Q: LMStudio连接失败？
# A: 确认LMStudio服务器已启动，端口号是否正确

## Q: 大模型响应太慢？
# A: 调整 MAX_TOKENS 参数，或使用更小的模型

## Q: AI分析结果不理想？
# A: 可以调整 TEMPERATURE 参数 (0.1-1.0)，数值越小回答越稳定